# ğŸ“š LlamaIndex - Document Chunking & Search System

> **Complete guide for using LlamaIndex to process, chunk, and search research documents**

---

## ğŸ¯ What is LlamaIndex?

LlamaIndex is a powerful framework for:
- **Loading** documents (PDF, DOCX, TXT)
- **Chunking** text into smaller pieces
- **Indexing** content for semantic search
- **Querying** documents with natural language

**No OpenAI API key required!** Works with local models.

---

## âœ… Installation Status

**âœ“ Installed:** LlamaIndex v0.14.5  
**âœ“ Location:** `r:\IDE\VLE\RESEARCHCLM\llamaindex_env\`  
**âœ“ Date:** October 16, 2025

---

## ğŸš€ Quick Start (60 Seconds)

### Step 1: Activate Environment
```powershell
cd r:\IDE\VLE\RESEARCHCLM
.\activate_llamaindex.ps1
```

### Step 2: Run Example
```powershell
python llamaindex_local_search.py
```

### Step 3: Search Your Documents
Type queries like:
- `behavioral change interventions`
- `climate policy recommendations`

**Done!** ğŸ‰

---

## ğŸ“– Documentation Files

| File | Purpose | When to Use |
|------|---------|-------------|
| **LLAMAINDEX_QUICKSTART.md** | Get started in 5 minutes | Start here! |
| **LLAMAINDEX_GUIDE.md** | Complete documentation | Deep dive |
| **LLAMAINDEX_INSTALLATION_SUMMARY.md** | What was installed | Reference |
| **README_LLAMAINDEX.md** | This file | Overview |

---

## ğŸ› ï¸ Available Scripts

### 1. PDF Chunker
**File:** `llamaindex_pdf_chunker.py`

**What it does:**
- Loads PDFs from `./sources/`
- Splits into chunks (512 chars)
- Exports to JSON

**Run:**
```powershell
python llamaindex_pdf_chunker.py
```

**Output:**
- `./llamaindex_output/pdf_chunks.json`
- `./llamaindex_output/chunking_stats.json`

---

### 2. Local Search
**File:** `llamaindex_local_search.py`

**What it does:**
- Creates searchable index (no API key!)
- Interactive search interface
- Shows similar chunks

**Run:**
```powershell
python llamaindex_local_search.py
```

**Features:**
- âœ“ No OpenAI API needed
- âœ“ Local embeddings
- âœ“ Real-time search

---

### 3. Research Pipeline
**File:** `llamaindex_research_pipeline.py`

**What it does:**
- Complete document processing
- Extracts metadata (titles, keywords)
- Creates comprehensive reports

**Run:**
```powershell
python llamaindex_research_pipeline.py
```

**Output:**
- `research_chunks.json` - Structured data
- `research_chunks.txt` - Readable format
- `processing_report.md` - Summary
- `vector_index/` - Searchable index

---

## ğŸ’¡ Key Concepts

### 1. Document Loading
```python
from llama_index.core import SimpleDirectoryReader

# Load all PDFs
documents = SimpleDirectoryReader(
    "./sources",
    required_exts=[".pdf"],
    recursive=True
).load_data()
```

### 2. Text Chunking
```python
from llama_index.core.node_parser import SentenceSplitter

# Split into chunks
splitter = SentenceSplitter(
    chunk_size=512,      # Max chars per chunk
    chunk_overlap=50     # Overlap between chunks
)

chunks = splitter.get_nodes_from_documents(documents)
```

### 3. Semantic Search
```python
from llama_index.core import VectorStoreIndex

# Create index
index = VectorStoreIndex(chunks)

# Search
results = index.as_retriever(similarity_top_k=5).retrieve("your query")
```

---

## ğŸ“Š Use Cases

### For Research Papers
```powershell
# Extract and chunk PDFs
python llamaindex_pdf_chunker.py

# Search for topics
python llamaindex_local_search.py
# Query: "behavioral interventions climate"
```

### For Policy Documents
```powershell
# Full pipeline with metadata
python llamaindex_research_pipeline.py

# Export results to JSON
# Use in your analysis scripts
```

### For Literature Review
```powershell
# Build searchable database
python llamaindex_local_search.py

# Query: "water conservation policy"
# Get relevant sections instantly
```

---

## ğŸ”§ Configuration

### Chunk Size Settings
Edit in scripts:
```python
CHUNK_SIZE = 512      # Characters per chunk
CHUNK_OVERLAP = 50    # Overlap between chunks
```

**Recommendations:**
- Academic papers: 512-1024
- Books: 1024-2048
- Abstracts: 256-512

### Search Settings
```python
# Number of results
top_k = 5             # Return top 5 matches

# Similarity threshold
similarity_threshold = 0.7  # 70% similar or more
```

---

## ğŸ” Example Queries

### Research Topics
```
"behavioral change interventions"
"climate policy recommendations"
"energy consumption patterns"
"water conservation strategies"
```

### Methodology Search
```
"randomized controlled trial"
"qualitative research methods"
"mixed methods approach"
"survey methodology"
```

### Specific Concepts
```
"social norms nudging"
"default choice architecture"
"feedback mechanisms"
"incentive structures"
```

---

## ğŸ“ˆ Workflow Integration

### With Existing Research Pipeline

```python
# Step 1: Extract chunks
python llamaindex_pdf_chunker.py

# Step 2: Load chunks into your analysis
import json
with open('llamaindex_output/pdf_chunks.json') as f:
    chunks = json.load(f)

# Step 3: Process with your scripts
for chunk in chunks:
    # Your analysis code
    analyze_text(chunk['text'])
```

### With Excel Workflow

```python
import pandas as pd

# Load chunks
with open('llamaindex_output/pdf_chunks.json') as f:
    chunks = json.load(f)

# Convert to DataFrame
df = pd.DataFrame(chunks)

# Save to Excel
df.to_excel('research_chunks.xlsx', index=False)
```

---

## ğŸ“ Advanced Features

### Metadata Extraction
```python
from llama_index.core.extractors import (
    TitleExtractor,
    KeywordExtractor
)

# Automatic metadata
extractors = [
    TitleExtractor(),
    KeywordExtractor(keywords=10)
]
```

### Filtered Search
```python
# Search specific files
filters = {"file_name": "climate_paper.pdf"}

results = index.as_retriever(
    filters=filters,
    similarity_top_k=5
).retrieve(query)
```

### Hierarchical Chunking
```python
from llama_index.core.node_parser import HierarchicalNodeParser

# Multi-level chunks
parser = HierarchicalNodeParser.from_defaults(
    chunk_sizes=[2048, 512, 128]
)
```

---

## ğŸ› ï¸ Troubleshooting

### Issue: Module not found
**Solution:**
```powershell
.\llamaindex_env\Scripts\Activate.ps1
```

### Issue: No PDFs found
**Solution:**
```powershell
# Add PDFs to sources folder
mkdir sources
# Copy your PDFs there
```

### Issue: Out of memory
**Solution:**
```python
# Use smaller chunks
CHUNK_SIZE = 256  # Instead of 512
```

### Issue: Slow processing
**Solution:**
```python
# Process fewer documents
documents = documents[:10]
```

---

## ğŸ“ Directory Structure

```
r:\IDE\VLE\RESEARCHCLM\
â”‚
â”œâ”€â”€ llamaindex_env/              # Virtual environment
â”‚
â”œâ”€â”€ sources/                     # Your PDFs (add here)
â”‚
â”œâ”€â”€ llamaindex_output/           # Chunk outputs
â”‚   â”œâ”€â”€ pdf_chunks.json
â”‚   â””â”€â”€ chunking_stats.json
â”‚
â”œâ”€â”€ llamaindex_local_index/      # Search index
â”‚
â”œâ”€â”€ llamaindex_research_output/  # Pipeline outputs
â”‚   â”œâ”€â”€ research_chunks.json
â”‚   â”œâ”€â”€ research_chunks.txt
â”‚   â””â”€â”€ processing_report.md
â”‚
â”œâ”€â”€ Scripts:
â”‚   â”œâ”€â”€ llamaindex_pdf_chunker.py
â”‚   â”œâ”€â”€ llamaindex_local_search.py
â”‚   â””â”€â”€ llamaindex_research_pipeline.py
â”‚
â””â”€â”€ Documentation:
    â”œâ”€â”€ LLAMAINDEX_QUICKSTART.md
    â”œâ”€â”€ LLAMAINDEX_GUIDE.md
    â”œâ”€â”€ LLAMAINDEX_INSTALLATION_SUMMARY.md
    â””â”€â”€ README_LLAMAINDEX.md (this file)
```

---

## ğŸ”— Quick Links

### Get Started
1. [Quick Start Guide](LLAMAINDEX_QUICKSTART.md) - Start here!
2. [Full Documentation](LLAMAINDEX_GUIDE.md) - Complete reference

### Run Scripts
```powershell
# Activate
.\activate_llamaindex.ps1

# Basic chunking
python llamaindex_pdf_chunker.py

# Local search
python llamaindex_local_search.py

# Full pipeline
python llamaindex_research_pipeline.py
```

### External Resources
- ğŸ“– [LlamaIndex Docs](https://docs.llamaindex.ai/)
- ğŸ’» [GitHub](https://github.com/run-llama/llama_index)
- ğŸ’¬ [Discord](https://discord.gg/dGcwcsnxhU)

---

## âœ… What You Can Do Now

### âœ“ Basic Tasks
- [x] Chunk PDFs into smaller pieces
- [x] Export chunks to JSON
- [x] Get document statistics

### âœ“ Search Tasks
- [x] Semantic search (no API key)
- [x] Interactive query interface
- [x] Find similar chunks

### âœ“ Advanced Tasks
- [x] Extract metadata (titles, keywords)
- [x] Create comprehensive reports
- [x] Build searchable knowledge base

---

## ğŸ¯ Next Steps

1. **âœ“ DONE:** Installation complete
2. **â†’ TODO:** Add PDFs to `./sources/`
3. **â†’ TODO:** Run chunker: `python llamaindex_pdf_chunker.py`
4. **â†’ TODO:** Try search: `python llamaindex_local_search.py`
5. **â†’ TODO:** Integrate with your workflow

---

## ğŸ“ Need Help?

### Documentation
- Quick questions â†’ [LLAMAINDEX_QUICKSTART.md](LLAMAINDEX_QUICKSTART.md)
- Detailed info â†’ [LLAMAINDEX_GUIDE.md](LLAMAINDEX_GUIDE.md)
- Installation â†’ [LLAMAINDEX_INSTALLATION_SUMMARY.md](LLAMAINDEX_INSTALLATION_SUMMARY.md)

### External Support
- Official docs: https://docs.llamaindex.ai/
- Community: https://discord.gg/dGcwcsnxhU
- Examples: https://github.com/run-llama/llama_index/tree/main/docs/examples

---

## ğŸ‰ Summary

**LlamaIndex is ready!**

âœ… **3 working scripts**  
âœ… **Complete documentation**  
âœ… **No API key needed**  
âœ… **Local embeddings included**  

**Start now:**
```powershell
.\activate_llamaindex.ps1
python llamaindex_local_search.py
```

**Happy researching! ğŸ“šğŸ”**

---

*Last updated: October 16, 2025*  
*Version: LlamaIndex 0.14.5*  
*Location: r:\IDE\VLE\RESEARCHCLM*




